{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e7fd80-7e5b-4670-97ab-b6eced3815c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, GlobalAveragePooling2D, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from dotenv.main import load_dotenv\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = os.environ['MODEL_NAME']\n",
    "\n",
    "\n",
    "# load datasets paths\n",
    "train_dataset_path = '../../' + MODEL_NAME + '/seg_train'\n",
    "validation_dataset_path = '../../' + MODEL_NAME + '/seg_test'\n",
    "num_classes = len(os.listdir(train_dataset_path))\n",
    "# resize images to 1/3:\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "# SIZE OF BATCH\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4fb091-ebcb-400c-bf58-6ab70161fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_model():\n",
    "    # model for multiple classes (labels)\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=128, kernel_size=(5, 5), padding='valid',\n",
    "               input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), padding='valid',\n",
    "               kernel_regularizer=l2(0.00005)),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), padding='valid',\n",
    "               kernel_regularizer=l2(0.00005)),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=num_classes, activation='softmax')\n",
    "    ])\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec41fbcc-6ae9-45d8-93a0-06f6b00481c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11121 images belonging to 4 classes.\n",
      "Found 2773 images belonging to 4 classes.\n",
      "Label Mappings for classes present in the training and validation datasets\n",
      "\n",
      "0 : brazil\n",
      "1 : japan\n",
      "2 : uk\n",
      "3 : us\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_it = datagen.flow_from_directory(train_dataset_path,\n",
    "                                           class_mode='categorical', batch_size=BATCH_SIZE, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "test_it = datagen.flow_from_directory(validation_dataset_path,\n",
    "                                          class_mode='categorical', batch_size=BATCH_SIZE, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "labels = {value: key for key,\n",
    "              value in train_it.class_indices.items()}\n",
    "print(\"Label Mappings for classes present in the training and validation datasets\\n\")\n",
    "for key, value in labels.items():\n",
    "    print(f\"{key} : {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a50886d4-312b-4c60-b528-bdfbdbbe5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11121 images belonging to 4 classes.\n",
      "Found 2773 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = create_model()\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    # prepare iterator\n",
    "train_it = datagen.flow_from_directory(train_dataset_path,\n",
    "                                           class_mode='categorical', batch_size=BATCH_SIZE, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "test_it = datagen.flow_from_directory(validation_dataset_path,\n",
    "                                          class_mode='categorical', batch_size=BATCH_SIZE, target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c8fb3-40c8-425d-a489-810c3b7028c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "348/348 [==============================] - 105s 285ms/step - loss: 1.4943 - accuracy: 0.3721 - val_loss: 1.6222 - val_accuracy: 0.3862\n",
      "Epoch 2/5\n",
      "348/348 [==============================] - 102s 291ms/step - loss: 1.2857 - accuracy: 0.3983 - val_loss: 1.2507 - val_accuracy: 0.4331\n",
      "Epoch 3/5\n",
      "348/348 [==============================] - 111s 318ms/step - loss: 1.2677 - accuracy: 0.4155 - val_loss: 1.5742 - val_accuracy: 0.3924\n",
      "Epoch 4/5\n",
      "348/348 [==============================] - 109s 313ms/step - loss: 1.2328 - accuracy: 0.4367 - val_loss: 1.4059 - val_accuracy: 0.4183\n",
      "Epoch 5/5\n",
      " 58/348 [====>.........................] - ETA: 1:16 - loss: 1.2116 - accuracy: 0.4639"
     ]
    }
   ],
   "source": [
    " # fit model\n",
    "history = model.fit(train_it,\n",
    "                        validation_data=test_it, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311085f-cdbb-46cb-ad56-9f612b733869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
